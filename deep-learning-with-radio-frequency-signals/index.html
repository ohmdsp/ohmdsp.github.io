<!doctype html><html lang=en-us><head><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no,viewport-fit=cover"><meta charset=utf-8><meta name=generator content="Hugo 0.123.7 with Arberia theme"><title>OhmDSP Site | Deep Learning with Radio Frequency Signals</title>
<link rel=canonical href=https://ohmdsp.github.io/deep-learning-with-radio-frequency-signals/><meta name=description content="Descrizione da rivedere se è un doppione subtitle"><meta name=author content><meta name=keywords content><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebPage","headline":"Deep Learning with Radio Frequency Signals","datePublished":"2016-03-16T19:57:40+08:00","dateModified":"2016-03-16T19:57:40+08:00","url":"https://ohmdsp.github.io/deep-learning-with-radio-frequency-signals/","description":"Descrizione da rivedere se è un doppione subtitle","keywords":["RF","ML","Deep Learning"],"mainEntityOfPage":{"@type":"WebPage","@id":"https://ohmdsp.github.io/"},"publisher":{"@type":"Organization","name":"OhmDSP Site","url":"https://ohmdsp.github.io/"}}</script><link rel=icon href=../favicon/favicon.ico><link rel=icon type=image/png sizes=16x16 href=../favicon/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=../favicon/favicon-32x32.png><link rel=apple-touch-icon href=../favicon/apple-touch-icon.png><link rel=mask-icon href=../favicon/safari-pinned-tab.svg><link rel=manifest href=../site.webmanifest><meta name=theme-color content="/"><meta name=msapplication-TileColor content="/"><link rel=stylesheet type=text/css href=../lib/bootstrap/css/bootstrap.min.css><link rel=stylesheet type=text/css href=../lib/lightbox/css/lightbox.css><link rel=stylesheet type=text/css href=../font-awesome-4.7.0/css/font-awesome.min.css><link rel=stylesheet type=text/css href=../gfonts/font.css><link rel=stylesheet href=https://ohmdsp.github.io/main.min.cd0e89a060caa38dbb22a636944f6f5546d4650fcb33393f71de3295fd988348.css><script>window.MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]],displayMath:[["$$","$$"],["\\[","\\]"]]},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],processHtmlClass:"mathjax",ignoreHtmlClass:"no-mathjax"}}</script><script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></head><body><nav class="navbar fixed-top navbar-expand-lg navbar-dark flex-column"><div class="container flex-row"><style>.navbar-brand{color:#fff!important;font-weight:700!important}</style><button class="navbar-toggler mr-3" type=button data-toggle=collapse data-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<span class=navbar-toggler-icon></span></button><div class="collapse navbar-collapse navbar-nav-scroll" id=navbarSupportedContent role=navigation aria-label="Main Navigation"><ul class="navbar-nav mr-5 flex-fill"><li class=nav-item><a class=nav-link href=../posts/>OhmDSP Blog</a></li><li class=nav-item><a class=nav-link href=../about/>About</a></li></ul><div class="collapse navbar-collapse navbar-nav-scroll" id=navbarSupportedContent role=navigation aria-label="Main Navigation"><div class="d-block d-lg-none"><ul class=navbar-nav><li class=nav-item><a class=nav-link href=../search title=Search><span class="d-block d-lg-none"><i class="fa fa-search" aria-hidden=true></i> Search</span><span class="d-none d-lg-block"><i class="fa fa-search" aria-hidden=true></i></span></a></li></ul></div><div class="d-none d-lg-flex align-items-center mr-2 flex-fill"><form class="form-inline ml-0" action=../search method=GET target=_self><a class="js-search-form-submit position-absolute" href=../search title=Search><i class="fa fa-search fa-fw text-muted pl-2" aria-hidden=true></i></a>
<input id=search-by class="search-field form-control form-control-md mr-sm-1 mr-lg-2 w-100" style=padding-left:2rem maxlength=50 data-search-input type=search placeholder=Search aria-label=Search name=q>
<input type=hidden name=_from value=nav></form></div></div></div></nav><div class="container main-content"><div class="row justify-content-center"><div class="col-md-10 col-lg-8 article"><div class="article-body page-body"><h1 class=text-center id=post-title>Deep Learning with Radio Frequency Signals<a class=headerlink href=../deep-learning-with-radio-frequency-signals/ title="Permanent link"></a></h1><p class="text-center text-muted">Learn to signal</p><picture><source media=(min-width:480px) srcset=../deep-learning-with-radio-frequency-signals/dsd_sc_hu2e1de638380ff2048b1bcb20f2b938b3_89603_960x0_resize_q75_h2_box.webp type=image/webp><source srcset=../deep-learning-with-radio-frequency-signals/dsd_sc_hu2e1de638380ff2048b1bcb20f2b938b3_89603_480x0_resize_q75_h2_box.webp type=image/webp><img loading=lazy class="img-fluid mx-auto d-block rounded mb-4" src=../deep-learning-with-radio-frequency-signals/dsd_sc.jpg height=1080 width=1920 type=image/jpeg alt=dsd_sc.jpg></picture><div class="row mb-1"><div class="col-2 col-md-1 p-0 ml-3 align-self-center"><a href><img src class="rounded-circle img-fluid w-100" sizes=10vw alt></a></div><div class="col pr-0 d-flex align-items-center"><p><span class=text-muted><span class=mr-2><a class=text-muted href target=_blank></a></span><br><span class="fa fa-clock-o"></span> <time>Mar 16, 2016</time>
<span class="ml-2 fa fa-tags" aria-hidden=true></span>
<a class="badge badge-light text-muted" href=../tags/rf/>RF</a>
<span class="ml-2 fa fa-tags" aria-hidden=true></span>
<a class="badge badge-light text-muted" href=../tags/ml/>ML</a>
<span class="ml-2 fa fa-tags" aria-hidden=true></span>
<a class="badge badge-light text-muted" href=../tags/deep-learning/>Deep Learning</a></span></p></div></div><p><strong>Signal Classification Using Spectrograms and Deep Learning</strong>
In this post, I will introduce some basic methods for utilizing a Convolutional Neural Network (CNN) to process spectrograms created from Radio Frequency (RF) data. The information in the post was taken from a tutorial my colleagues and I provided to NVidia Corporation in early 2015 that has been used in their enterprise training series for several years. This post links you to a git project that removes the dependency on Nvidia&rsquo;s DIGITS platform and uses only Keras and Tensorflow.
<a href=https://github.com/ohmdsp/mldsd>Project Code & Data</a></p><p><strong>Introduction to signal detection</strong>
When monitoring radio frequency (RF) signals, or similar signals from sensors such as biomedical, temperature, etc., we are often interested in detecting certain signal “markers” or features. This can become a challenging problem when the signal-of-interest is degraded by noise. Traditional signal detection methods use a range of techniques such as energy detection, matched filtering, or other correlation-based processing techniques.</p><figure><img src=../images/dsd_conf.png style=width:700px;height:580px><figcaption>Figure 1. Signal classification confusion matrix.</figcaption></figure>Short-duration radio frequency (RF) events can be especially challenging to detect, since the useful data length is limited and long integration times are not possible. Weak signals that are short in duration are some of the most difficult to reliably detect (or even find). I will walk you through a simple approach using a Convolutional Neural Network (CNN) to tackle the traditional signal processing problem of detecting RF signals in noise.<br><br><p><strong>A little background information</strong>
Signal detection theory often assumes that a signal is corupted with additive white Gaussian noise (AWGN). This type of noise is common in the real world and the assumption makes mathematical analysis tractable. The detection of a signal in noise depends on the signal duration, amplitude, and the corresponding noise process. This becomes more difficult if correlated noise, or interfering signals, are also in the same band as the signal you wish to detect.</p><p>In this tutorial, we will assume no a-priori information about the parameters for the signal-of-interest. As input to the Convolutional Neural Network, we will utilize spectrograms computed from simulated Radio Frequency (RF) data using a common Fast Fourier Transform (FFT) based method. Taking the input data into the frequency domain as time-frequency grams, which are 2D representations just like images, allows us to visualize the energy of a signal over some pre-determined time duration and frequency bandwidth.</p><figure><img src=../images/dsd_2.png style=width:520px;height:460px><figcaption>Figure 2. Multiple signals and noise (x-axis is time, y-axis is frequency).</figcaption></figure><p><strong>The difficulty with real-world signals</strong><br>For a single sinusoid in AWGN, finding the frequency bin with the maximum amplitude is a method for estimating signal frequency in a spectrogram. But real-world signals are often more complex, with frequency components that change with time, and creating a generalized signal detection algorithm becomes difficult. In this tutorial, we will look at one of these types of signals - Linear Frequency-Modulated (LFM) signals. In a follow-on tutorial we will explore Frequency-Hopped (FH) signals and multi-signal detection scenarios.<br></p><p><strong>Linear Frequency-Modulated Signals</strong><br>A linear frequency-modulated (LFM), or chirp, signal is a signal that ramps up or down in frequency over some time frame. Its frequency changes with time based on its chirp rate. Chirps are used in many different systems for frequency response measurements and timing. RADAR systems use chirp signals due to the inherent large time-bandwith product available with coherent processing. Another common use is for automatic room equalization in home theater receivers, since chirps can excite a large frequency swath quickly. Chirps can also be used as “pilot” signals to denote the start of an incoming transmission, and more. Figure 3 shows a high-SNR chirp as seen in a grayscale spectrogram (the format we will be using). Since the spectrogram consists of real numbers all > 0, we can map it to an image file by scaling the values appropriately. So we only need a single grayscale image channel. In this plot, the x axis is time and the y axis is frequency. Brightness is proportional to signal power.</p><figure><img src=../images/dsd_1.png style=width:520px;height:460px><figcaption>Figure 3. High-SNR chip spectrogram (grayscale).</figcaption></figure><figure><img src=../images/dsd_3.png style=width:520px;height:460px><figcaption>Figure 4. Weak chirp embedded in noise with other signals (x-axis is time, y-axis is frequency).</figcaption></figure><p><strong>Give it a try</strong><br>You can try using deep learning yourself by following the link to my git page at the top of this post. There you will find a jupiter notebook. Modify the paths to point to the images of your time-frequency grams or reach out to me on LinkedIn and I will send you a dataset to use. When you are done you should have a trained model for classifying/detecting &ldquo;chirps&rdquo;, &ldquo;CW&rdquo;, and &ldquo;Hopped&rdquo; signal types. You can see a sample of my output results in Figure 5 below. Have fun!</p><figure><img src=../images/dsd_4.png style=width:680px><figcaption>Figure 5. Example results from signal classifier.</figcaption></figure></div></div></div></div><footer class=footer><div class=container><p class="small text-center text-muted w-75 mx-auto">&copy 2012–2025 OhmDSP Site&nbsp;⋅
<a href=../contact>Contact</a>&nbsp;</div></footer><script type=text/javascript src=../lib/jquery/jquery.js></script><script type=text/javascript src=../lib/popper/popper.js></script><script type=text/javascript src=../lib/bootstrap/js/bootstrap.min.js></script><script type=text/javascript src=../lib/lightbox/js/lightbox.js></script><script>var lightbox=GLightbox(),lightboxDescription,lightboxVideo,lightboxInlineIframe;lightbox.on("open",e=>{console.log("lightbox opened")}),lightboxDescription=GLightbox({selector:".glightbox2"}),lightboxVideo=GLightbox({selector:".glightbox3"}),lightboxVideo.on("slide_changed",({prev:e,current:t})=>{console.log("Prev slide",e),console.log("Current slide",t);const{slideIndex:s,slideNode:o,slideConfig:i,player:n}=t;n&&(n.ready||n.on("ready",e=>{}),n.on("play",e=>{console.log("Started play")}),n.on("volumechange",e=>{console.log("Volume change")}),n.on("ended",e=>{console.log("Video ended")}))}),lightboxInlineIframe=GLightbox({selector:".glightbox4"})</script><script type=text/javascript src=../lib/back-to-top/vanilla-back-to-top.min.js></script><script>addBackToTop({diameter:56,backgroundColor:"rgb(255, 82, 82)",textColor:"#fff"})</script></body></html>